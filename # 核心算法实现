# 核心模块：NMI_KSG.py
import numpy as np
from scipy.special import digamma
from sklearn.neighbors import KDTree

class NMLKSG:
    def __init__(self, k=5, delta=0.05, random_state=42):
        """
        初始化参数 (依据权利要求5和实施例1-2)
        :param k: 近邻数 (3≤k≤10)
        :param delta: 条件独立阈值 (0.03≤δ≤0.07)
        :param random_state: 随机种子 (实施例1)
        """
        self.k = k
        self.delta = delta
        self.random_state = random_state
        
    def _ksg_estimate(self, X, Y):
        """
        KSG互信息估计 (权利要求1-c)
        """
        N = len(X)
        Z = np.hstack((X, Y))  # 联合空间
        
        # 构建KD树 (说明书Page2)
        tree_Z = KDTree(Z, metric='chebyshev')  # 切比雪夫距离
        
        sum_psi = 0
        for i in range(N):
            # 查询第k近邻 (说明书实施例1)
            dist, idx = tree_Z.query(Z[i:i+1], k=self.k+1)  # 含自身点
            eps = dist[0, -1]  # 第k近邻距离
            
            # 统计邻居数 (权利要求1-b)
            n_x = self._count_neighbors(X, X[i], eps)
            n_y = self._count_neighbors(Y, Y[i], eps)
            
            # Digamma累加 (说明书Page1公式)
            sum_psi += digamma(n_x) + digamma(n_y)
        
        # KSG互信息公式 (权利要求1-c)
        MI = digamma(self.k) + digamma(N) - sum_psi/N
        return MI
    
    def _entropy_estimate(self, X):
        """
        熵估计 (权利要求1-d)
        """
        N = len(X)
        tree_X = KDTree(X, metric='chebyshev')
        sum_psi = 0
        
        for i in range(N):
            dist, idx = tree_X.query(X[i:i+1], k=self.k+1)
            eps = dist[0, -1]
            n_x = self._count_neighbors(X, X[i], eps)
            sum_psi += digamma(n_x)
        
        # 熵估计公式 (说明书Page1)
        H = digamma(N) - digamma(self.k) + sum_psi/N
        return H
    
    def _count_neighbors(self, space, point, eps):
        """
        统计ε半径内邻居数 (说明书实施例1)
        """
        dists = np.max(np.abs(space - point), axis=1)  # 切比雪夫距离
        return np.sum(dists <= eps) - 1  # 排除自身点
    
    def compute_nmi(self, X, Y):
        """
        归一化互信息计算 (权利要求1)
        """
        MI = self._ksg_estimate(X, Y)
        H_x = self._entropy_estimate(X)
        H_y = self._entropy_estimate(Y)
        
        # 归一化互信息 (说明书Page1)
        return MI / np.sqrt(H_x * H_y)
    
    def conditional_nmi(self, X, Y, Z):
        """
        条件归一化互信息 (权利要求4)
        """
        # 条件互信息估计 (说明书Page2)
        MI_cond = self._ksg_estimate(np.hstack((X,Z)), Y) - self._ksg_estimate(Z, Y)
        
        # 条件熵估计
        H_xz = self._entropy_estimate(np.hstack((X,Z)))
        H_yz = self._entropy_estimate(np.hstack((Y,Z)))
        
        # 条件归一化互信息
        cond_nmi = MI_cond / np.sqrt(H_xz * H_yz)
        
        # 条件独立判定 (权利要求4-b)
        independent = cond_nmi < self.delta
        return cond_nmi, independent

# 应用模块：Applications.py
class NMIApplications:
    @staticmethod
    def feature_selection(X, y, top_k=5):
        """
        特征选择 (权利要求2)
        """
        n_features = X.shape[1]
        nmi_scores = []
        
        for i in range(n_features):
            nmi = NMLKSG(k=5).compute_nmi(X[:, i:i+1], y)
            nmi_scores.append((i, nmi))
        
        # 按NMI排序 (说明书实施例2)
        return sorted(nmi_scores, key=lambda x: x[1], reverse=True)[:top_k]
    
    @staticmethod
    def spectral_clustering(X, n_clusters):
        """
        谱聚类 (权利要求3)
        """
        n = len(X)
        S = np.zeros((n, n))
        
        # 构建NMI相似矩阵 (说明书实施例3)
        for i in range(n):
            for j in range(i+1, n):
                S[i,j] = NMLKSG().compute_nmi(X[i:i+1], X[j:j+1])
                S[j,i] = S[i,j]
        
        # 谱聚类 (说明书实施例3)
        from sklearn.cluster import SpectralClustering
        model = SpectralClustering(n_clusters=n_clusters, affinity='precomputed')
        return model.fit_predict(S)
    
    @staticmethod
    def causal_discovery(X, Y, Z_candidates):
        """
        因果发现 (权利要求4)
        """
        # PC算法框架 (说明书实施例4)
        causal_edges = []
        for Z in Z_candidates:
            cond_nmi, independent = NMLKSG().conditional_nmi(X, Y, Z)
            if not independent:
                causal_edges.append((Z, cond_nmi))
        
        return sorted(causal_edges, key=lambda x: x[1], reverse=True)
